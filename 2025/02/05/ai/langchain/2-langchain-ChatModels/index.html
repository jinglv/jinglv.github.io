<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"jinglv.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="学习LangChain学习笔记第二讲">
<meta property="og:type" content="article">
<meta property="og:title" content="LangChain组件ChatModels（磨平不同LLM的差异）">
<meta property="og:url" content="https://jinglv.github.io/2025/02/05/ai/langchain/2-langchain-ChatModels/index.html">
<meta property="og:site_name" content="Jean&#39;s Blog">
<meta property="og:description" content="学习LangChain学习笔记第二讲">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://jing-images.oss-cn-beijing.aliyuncs.com/img/image-20250829091634751.png">
<meta property="og:image" content="https://jing-images.oss-cn-beijing.aliyuncs.com/img/image-20250829144113686.png">
<meta property="og:image" content="https://jing-images.oss-cn-beijing.aliyuncs.com/img/image-20250829144444032.png">
<meta property="article:published_time" content="2025-02-04T16:00:00.000Z">
<meta property="article:modified_time" content="2025-08-28T09:00:00.000Z">
<meta property="article:author" content="Jean Lv">
<meta property="article:tag" content="LangChain">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jing-images.oss-cn-beijing.aliyuncs.com/img/image-20250829091634751.png">

<link rel="canonical" href="https://jinglv.github.io/2025/02/05/ai/langchain/2-langchain-ChatModels/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>LangChain组件ChatModels（磨平不同LLM的差异） | Jean's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Jean's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Jean's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">一个专注软件测试开发技术的个人博客</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://jinglv.github.io/2025/02/05/ai/langchain/2-langchain-ChatModels/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Jean Lv">
      <meta itemprop="description" content="涉猎的主要编程语言Java、Python, 领域软件测试、AI测试开发相关">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jean's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          LangChain组件ChatModels（磨平不同LLM的差异）
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-02-05 00:00:00" itemprop="dateCreated datePublished" datetime="2025-02-05T00:00:00+08:00">2025-02-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-08-28 17:00:00" itemprop="dateModified" datetime="2025-08-28T17:00:00+08:00">2025-08-28</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LangChain/" itemprop="url" rel="index"><span itemprop="name">LangChain</span></a>
                </span>
            </span>

          
            <div class="post-description">学习LangChain学习笔记第二讲</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="ChatModels-amp-LLMs"><a href="#ChatModels-amp-LLMs" class="headerlink" title="ChatModels &amp; LLMs"></a>ChatModels &amp; LLMs</h1><p><img src="https://jing-images.oss-cn-beijing.aliyuncs.com/img/image-20250829091634751.png" alt="image-20250829091634751" style="zoom:50%;" /></p>
<p>LangChain中的大模型组件主要分为ChatModels和LLMs两类，ChatModels支持OpenAI和LangChain两种消息格式、工具调用、结构化输出及多模态处理，适用于现代对话场景；而LLMs仅支持字符串输入输出，功能较单一，已逐渐被弃用。此外，LongChain 0.3版本后对依赖包进行了拆分，分为官方合作包（如ChatOpenAI）和社区开发包（如LangChain Community），前者由官方维护，适配主流模型，后者由社区贡献，灵活性较高但维护性较差。实际开发中推荐使用ChatModels和官方合作包以确保兼容性和稳定性。</p>
<ul>
<li>ChatModels具备工具调用能力（Tool Call / Function Call）并支持结构化输出如JSON/XML</li>
<li>ChatModels支持多模态输入输出，包括文本、音频、图像等</li>
<li>LLMs是早期版本遗留下来的模式，目前已逐渐被Chat Modules取代</li>
<li>通过函数名前缀判断模块类型：Chat开头的是ChatModels，LLM结尾的是llms</li>
</ul>
<p>LangChain包相关的：</p>
<ul>
<li>官方合作包：<a target="_blank" rel="noopener" href="https://python.langchain.com/docs/integrations/providers/">https://python.langchain.com/docs/integrations/providers/</a></li>
<li>社区开发包：<a target="_blank" rel="noopener" href="https://python.langchain.com/docs/integrations/chat/">https://python.langchain.com/docs/integrations/chat/</a></li>
</ul>
<h2 id="大模型的接入示例"><a href="#大模型的接入示例" class="headerlink" title="大模型的接入示例"></a>大模型的接入示例</h2><h3 id="OpenAI接入"><a href="#OpenAI接入" class="headerlink" title="OpenAI接入"></a>OpenAI接入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=<span class="string">&quot;gpt-4&quot;</span>,</span><br><span class="line">    temperature=<span class="number">0</span>,</span><br><span class="line">    api_key=os.environ.get(<span class="string">&quot;OPENAI_API_KEY&quot;</span>),</span><br><span class="line">    base_url=os.environ.get(<span class="string">&quot;OPENAI_API_BASE&quot;</span>),</span><br><span class="line">    )</span><br><span class="line">llm.invoke(<span class="string">&quot;介绍下你自己&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="DeepSeek接入"><a href="#DeepSeek接入" class="headerlink" title="DeepSeek接入"></a>DeepSeek接入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> langchain_deepseek <span class="keyword">import</span> ChatDeepSeek</span><br><span class="line"></span><br><span class="line">llm = ChatDeepSeek(</span><br><span class="line">    model=<span class="string">&quot;Pro/deepseek-ai/DeepSeek-R1&quot;</span>,</span><br><span class="line">    temperature=<span class="number">0</span>,</span><br><span class="line">    api_key=os.environ.get(<span class="string">&quot;DEEPSEEK_API_KEY&quot;</span>),</span><br><span class="line">    api_base=os.environ.get(<span class="string">&quot;DEEPSEEK_API_BASE&quot;</span>),</span><br><span class="line">)</span><br><span class="line">llm.invoke(<span class="string">&quot;介绍下自己&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="Anthropic接入"><a href="#Anthropic接入" class="headerlink" title="Anthropic接入"></a>Anthropic接入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> langchain_anthropic <span class="keyword">import</span> ChatAnthropic</span><br><span class="line"></span><br><span class="line">model = ChatAnthropic(</span><br><span class="line">    model=<span class="string">&#x27;claude-3-5-sonnet-latest&#x27;</span>,</span><br><span class="line">    api_key=os.environ.get(<span class="string">&quot;ANTHROPIC_API_KEY&quot;</span>),</span><br><span class="line">    base_url=os.environ.get(<span class="string">&quot;ANTHROPIC_BASE_URL&quot;</span>),</span><br><span class="line">)</span><br><span class="line">model.invoke(<span class="string">&quot;介绍下自己&quot;</span>)</span><br></pre></td></tr></table></figure>
<h1 id="标准参数、事件、与输入输出"><a href="#标准参数、事件、与输入输出" class="headerlink" title="标准参数、事件、与输入输出"></a>标准参数、事件、与输入输出</h1><p>学习了大模型组件的标准参数和事件，包括模型名称、随机度（temperature）、超时时间、输出长度限制等配置，以及调用模型的主要方法如Invoke、Stream、Batch和异步流式输出。通过合理设置这些参数和使用不同事件，可以提升应用的交互体验和功能实现。</p>
<h2 id="标准参数"><a href="#标准参数" class="headerlink" title="标准参数"></a>标准参数</h2><h3 id="补全参数-Completion-Params"><a href="#补全参数-Completion-Params" class="headerlink" title="补全参数 (Completion Params)"></a>补全参数 (Completion Params)</h3><p>这些参数主要用于控制生成文本的特性。</p>
<ul>
<li><strong><code>model</code></strong>: 要使用的 OpenAI 模型的名称，类型为 <strong><code>str</code></strong>。</li>
<li><strong><code>temperature</code></strong>: 采样温度，类型为 <strong><code>float</code></strong>。该值越高，生成文本的随机性越强；反之，值越低，生成文本的确定性越强。</li>
<li><strong><code>max_tokens</code></strong>: 要生成的最大 token 数量，类型为可选的 <strong><code>int</code></strong>。这决定了生成文本的长度上限。</li>
<li><strong><code>logprobs</code></strong>: 是否返回每个生成 token 的对数概率，类型为可选的 <strong><code>bool</code></strong>。这对于分析模型预测的置信度很有用。</li>
<li><strong><code>stream_options</code></strong>: 配置流式输出的选项，类型为 <strong><code>Dict</code></strong>。例如，可以设置 <code>&#123;&quot;include_usage&quot;: True&#125;</code> 来在流式传输时返回 token 使用情况。</li>
<li><strong><code>use_responses_api</code></strong>: 是否使用 <code>responses</code> API，类型为可选的 <strong><code>bool</code></strong>。</li>
<li><strong>stop</strong>：指定停止字符</li>
</ul>
<h3 id="客户端参数-Client-Params"><a href="#客户端参数-Client-Params" class="headerlink" title="客户端参数 (Client Params)"></a>客户端参数 (Client Params)</h3><p>这些参数主要用于配置客户端与 OpenAI API 的交互方式。</p>
<ul>
<li><strong><code>timeout</code></strong>: 请求的超时时间，类型为 <strong><code>Union[float, Tuple[float, float], Any, None]</code></strong>。可以是一个浮点数表示总超时时间，也可以是一个元组来分别指定连接和读取超时时间。</li>
<li><strong><code>max_retries</code></strong>: 最大重试次数，类型为可选的 <strong><code>int</code></strong>。当请求失败时，客户端会尝试重新发送请求，此参数决定了最大重试次数。</li>
<li><strong><code>api_key</code></strong>: OpenAI API 密钥，类型为可选的 <strong><code>str</code></strong>。如果未在此处传入，将从环境变量 <code>OPENAI_API_KEY</code> 中读取。</li>
<li><strong><code>base_url</code></strong>: API 请求的基础 URL，类型为可选的 <strong><code>str</code></strong>。只有在使用代理或服务模拟器时才需要指定。</li>
<li><strong><code>organization</code></strong>: OpenAI 组织 ID，类型为可选的 <strong><code>str</code></strong>。如果未传入，将从环境变量 <code>OPENAI_ORG_ID</code> 中读取。</li>
<li><strong>rater_limiter</strong>：请求速率限制</li>
</ul>
<p>注意：</p>
<ul>
<li>标准参数只对本身API开发了相关参数的模型有用，比如有的模型本身没有指定的max_token，则其在LangChain中也无效</li>
<li>标准参数仅在官方合作包中强制要求，社区开发包不做强制要求</li>
</ul>
<p>根据标准参数，大模型初始化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=<span class="string">&quot;gpt-4&quot;</span>,</span><br><span class="line">    temperature=<span class="number">0.4</span>,</span><br><span class="line">    api_key=os.environ.get(<span class="string">&quot;OPENAI_API_KEY&quot;</span>),</span><br><span class="line">    base_url=os.environ.get(<span class="string">&quot;OPENAI_API_BASE&quot;</span>),</span><br><span class="line">    timeout=<span class="number">30</span>,</span><br><span class="line">    max_tokens=<span class="number">200</span>,</span><br><span class="line">    stop=<span class="string">&quot;我&quot;</span>, <span class="comment"># 停止字符，遇到“我”则会停止输出</span></span><br><span class="line">    max_retries = <span class="number">3</span></span><br><span class="line">    )</span><br><span class="line">llm.invoke(<span class="string">&quot;介绍下你自己&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="标准事件"><a href="#标准事件" class="headerlink" title="标准事件"></a>标准事件</h2><ul>
<li>invoke：模型主要调用方法，输入list，输出list</li>
<li>stream：流式输出方法</li>
<li>batch：批量模型请求方法</li>
<li>bind_tools：在模型执行的时候绑定工具</li>
<li>with_structured_output：给予invoke的结构化输出</li>
</ul>
<h3 id="其他有用事件"><a href="#其他有用事件" class="headerlink" title="其他有用事件"></a>其他有用事件</h3><ul>
<li>ainvoke：异步调用模型方法</li>
<li>astream：异步流式输出</li>
<li>abatch：异步的批量处理</li>
<li>astream_events：异步流事件，支持更细粒度的控制</li>
<li>with_retry：调用失败时才重试</li>
<li>with_fallback：失败恢复事件</li>
<li>configurble_fields：模型运行时的运行参数，适用于复杂的应用开发场景</li>
</ul>
<p>标准事件，代码示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=<span class="string">&quot;gpt-4&quot;</span>,</span><br><span class="line">    temperature=<span class="number">0</span>,</span><br><span class="line">    api_key=os.environ.get(<span class="string">&quot;OPENAI_API_KEY&quot;</span>),</span><br><span class="line">    base_url=os.environ.get(<span class="string">&quot;OPENAI_API_BASE&quot;</span>),</span><br><span class="line">    )</span><br><span class="line">question = <span class="string">&quot;langchain是什么?&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># invoke事件</span></span><br><span class="line">llm.invoke(question)</span><br><span class="line"></span><br><span class="line"><span class="comment"># stream事件</span></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> llm.stream(question):</span><br><span class="line">    <span class="built_in">print</span>(chunk.content+<span class="string">&quot;|&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># batch事件</span></span><br><span class="line">llm.batch([<span class="string">&quot;langchain作者是谁？&quot;</span>, <span class="string">&quot;Langchain的竞品有哪些？&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 异步事件流</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">for</span> event <span class="keyword">in</span> llm.astream_events(<span class="string">&quot;介绍下LangChain&quot;</span>, version=<span class="string">&quot;v2&quot;</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;event=<span class="subst">&#123;event[<span class="string">&#x27;event&#x27;</span>]&#125;</span> | name=<span class="subst">&#123;event[<span class="string">&#x27;name&#x27;</span>]&#125;</span> | data=<span class="subst">&#123;event[<span class="string">&#x27;data&#x27;</span>]&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>标准事件之结构化输出 - with_structured_output，代码示例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标准事件之结构化输出 - with_structured_output</span></span><br><span class="line"><span class="comment"># 影响LLM的输出</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Optional</span></span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel, Field</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=<span class="string">&quot;gpt-4&quot;</span>,</span><br><span class="line">    temperature=<span class="number">0</span>,</span><br><span class="line">    api_key=os.environ.get(<span class="string">&quot;OPENAI_API_KEY&quot;</span>),</span><br><span class="line">    base_url=os.environ.get(<span class="string">&quot;OPENAI_API_BASE&quot;</span>),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Joke</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Joke to tell user.&quot;&quot;&quot;</span></span><br><span class="line">    setup: <span class="built_in">str</span> = Field(description=<span class="string">&quot;The setup of the joke&quot;</span>)</span><br><span class="line">    punchline: <span class="built_in">str</span> = Field(description=<span class="string">&quot;The punchline to the joke&quot;</span>)</span><br><span class="line">    rating: <span class="type">Optional</span>[<span class="built_in">int</span>] = Field(</span><br><span class="line">        default=<span class="literal">None</span>, description=<span class="string">&quot;How funny the joke is, from 1 to 10&quot;</span></span><br><span class="line">    )</span><br><span class="line">structured_llm = llm.with_structured_output(Joke)</span><br><span class="line">structured_llm.invoke(<span class="string">&quot;给我讲一个关于程序员的笑话&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="数据通信的格式"><a href="#数据通信的格式" class="headerlink" title="数据通信的格式"></a>数据通信的格式</h2><h3 id="OpenAI-Messages"><a href="#OpenAI-Messages" class="headerlink" title="OpenAI Messages"></a>OpenAI Messages</h3><ul>
<li>SystemMessage：用于传导对话的内容</li>
<li>HumanMessage：用户输入的内容</li>
<li>AIMessage：模型响应的内容</li>
<li>多模型</li>
</ul>
<h3 id="LangChain-Messages"><a href="#LangChain-Messages" class="headerlink" title="LangChain Messages"></a>LangChain Messages</h3><ul>
<li>SystemMessage：系统角色</li>
<li>HumanMessage：用户角色</li>
<li>AIMessage：应用助理角色</li>
<li>AIMessageChunk：应用助理流式输出</li>
<li>ToolMessage：工具角色</li>
<li>RemoveMessage：LangGraph聊天记录</li>
</ul>
<h3 id="AIMessage"><a href="#AIMessage" class="headerlink" title="AIMessage"></a>AIMessage</h3><p>AI返回的数据</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>属性</th>
<th>标准化</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>content</td>
<td>原生</td>
<td>通常为字符串，但也可以时内容块列表</td>
</tr>
<tr>
<td>tool_calls</td>
<td>标准化</td>
<td>与消息相关的工具调用</td>
</tr>
<tr>
<td>invalid_tool_calls</td>
<td>标准化</td>
<td>工具调用与消息相关的解析错误</td>
</tr>
<tr>
<td>usage_metadata</td>
<td>标准化</td>
<td>元数据（输入输出token数，总计token数等）</td>
</tr>
<tr>
<td>id</td>
<td>标准化</td>
<td>消息唯一标识</td>
</tr>
<tr>
<td>response_metadata</td>
<td>原生</td>
<td>响应元数据（响应头、token计数等）</td>
</tr>
</tbody>
</table>
</div>
<p>注意：不同的大模型提供的内容属性并不相同目前行业暂无统一标准</p>
<h1 id="模型上下文窗口与token"><a href="#模型上下文窗口与token" class="headerlink" title="模型上下文窗口与token"></a>模型上下文窗口与token</h1><p>大模型的上下文窗口是指模型一次可处理的最大文本长度，受限于计算复杂度、硬件显存和训练数据长度。窗口过长会导致内存和计算需求激增，并可能因注意力衰减影响长文效果。解决方式包括引入外挂记忆（如REG）、滑动窗口技术及新架构探索。Token是模型处理的基本单位，其信息密度高于字符，且不同模型支持的窗口长度不一，应用时需注意控制输入输出长度以避免溢出问题。</p>
<h2 id="什么是上下文窗口"><a href="#什么是上下文窗口" class="headerlink" title="什么是上下文窗口"></a>什么是上下文窗口</h2><p>是大模型一次最多可以处理上下文的长度，根据模型有关，跟以下相关：</p>
<ul>
<li>计算复杂度：Transformer架构自注意力机制计算复杂度O(n²)，其中n是序列长度，当n增长时，内存和计算需求呈平方增长</li>
<li>硬件限制：GPU显存有限，处理长序列需要更多显存，序列越长模型响应时间越长</li>
<li>训练数据限制：预训练数据大多为短文本、长文本比较少，模型难以学习长距离依赖关系</li>
<li>注意衰减：随着序列长度增加，模型会对早期信息注意力下降，从而造成遗忘和长文质量不佳现象</li>
</ul>
<h2 id="模型的token"><a href="#模型的token" class="headerlink" title="模型的token"></a>模型的token</h2><ul>
<li>token事大模型处理信息的基本单位，将文本转化为机器更容易处理的形式，token并非等同于字符或单词，1token不等于1汉子</li>
<li>token可以是一个字一个词一句话一部分图片信息</li>
<li>token具有更高的语言浓缩能力，比原始字符更高效地表达语义和上下文关系</li>
<li>给机器读的语言</li>
<li>不同模型对token的定义和切分方式有所不同，例如OpenAI中的一个token约等于4个英文字符，3/4个单词</li>
<li>应用中需要注意token不能超出模型上下文窗口的限制</li>
</ul>
<h2 id="token的监控与追踪"><a href="#token的监控与追踪" class="headerlink" title="token的监控与追踪"></a>token的监控与追踪</h2><ul>
<li>大多数模型支持token消耗的追踪，用于统计费用及优化性能。</li>
<li>LangChain中可通过usage字段获取详细的token用量信息，包括输入、输出token数。</li>
<li>不同平台（如DeepSeek、OpenAI）的token元数据字段名称略有差异，但用途一致。</li>
<li>支持流式输出时的token追踪，尤其在OpenAI API中可以通过stream usage开启。</li>
</ul>
<h1 id="速率限制与缓存机制"><a href="#速率限制与缓存机制" class="headerlink" title="速率限制与缓存机制"></a>速率限制与缓存机制</h1><p>在实际应用中，很多模型如DeepSeek对其API有速率限制，主要是因为用户量增长快导致API压力大，为防止服务不可用，各家都会进行限制。以OpenAI为例，不同用户类型和模型有不同的速率限制标准，如免费用户每分钟只能请求三次，付费用户则相对宽松。为应对速率限制，通常会引入缓存机制减少模型调用频率，同时也可以通过设置速率控制参数（如RateLimiter）来避免超出限制，从而提升系统稳定性和用户体验。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>账户类型</th>
<th>Text &amp; Embedding(文本和嵌入)</th>
<th>Chat (聊天对话)</th>
<th>Edit (编辑)</th>
<th>Image (图像)</th>
<th>Audio (音频)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Free trial users(免费试用用户)</strong></td>
<td>3 RPM, 150,000 TPM</td>
<td>3 RPM, 40,000 TPM</td>
<td>3 RPM, 150,000 TPM</td>
<td>5 images / min</td>
<td>3 RPM</td>
</tr>
<tr>
<td><strong>按需付费用户 (前 48 小时)</strong></td>
<td>60 RPM, 250,000 TPM</td>
<td>60 RPM, 60,000 TPM</td>
<td>20 RPM, 150,000 TPM</td>
<td>50 images / min</td>
<td>50 RPM</td>
</tr>
<tr>
<td><strong>按量付费用户 (48 小时后)</strong></td>
<td>3,500 RPM, 350,000 TPM</td>
<td>3,500 RPM, 90,000 TPM</td>
<td>20 RPM, 150,000 TPM</td>
<td>50 images / min</td>
<td>50 RPM</td>
</tr>
</tbody>
</table>
</div>
<p><em>备注：</em></p>
<ul>
<li><strong>RPM</strong> (Requests Per Minute)：每分钟请求数。</li>
<li><strong>TPM</strong> (Tokens Per Minute)：每分钟 Token 数。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">graph TD</span><br><span class="line">A[用户问题] --&gt; B[是否相同]</span><br><span class="line">	B --&gt; C(缓存层)</span><br><span class="line">	B --&gt; D(LLM)</span><br></pre></td></tr></table></figure>
<p>缓存层：</p>
<ul>
<li>长期缓存</li>
<li>短期缓存</li>
</ul>
<p>速率限制示例代码</p>
<p>langchain中的InMemoryRateLimiter（写入内存）只能限制单位时间内的请求数量， 无法处理根据请求大小来限制的情况</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain_core.rate_limiters <span class="keyword">import</span> InMemoryRateLimiter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">rate_limiter = InMemoryRateLimiter(</span><br><span class="line">    requests_per_second=<span class="number">1</span>,  <span class="comment"># 每1秒请求一次</span></span><br><span class="line">    check_every_n_seconds=<span class="number">0.1</span>,  <span class="comment"># 每100毫秒检查一次是否允许</span></span><br><span class="line">    max_bucket_size=<span class="number">10</span>,  <span class="comment"># 控制最大突发大小</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">api_base = os.getenv(<span class="string">&quot;OPENAI_API_BASE&quot;</span>)</span><br><span class="line">api_key = os.getenv(<span class="string">&quot;OPENAI_API_KEY&quot;</span>)</span><br><span class="line"></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    temperature=<span class="number">0.0</span>,</span><br><span class="line">    base_url=api_base,</span><br><span class="line">    api_key=api_key,</span><br><span class="line">    rate_limiter=rate_limiter <span class="comment">#请求速率限制</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h1 id="大模型工具调用原理"><a href="#大模型工具调用原理" class="headerlink" title="大模型工具调用原理"></a>大模型工具调用原理</h1><p>大模型工具调用是指在应用开发中，让模型具备调用外部工具的能力，区别于普通使用方式。通过绑定工具（如数据库查询、天气API等），模型可根据用户问题判断是否需要调用工具，并生成结构化数据请求工具执行，获取实时信息或处理复杂任务（如数学运算），从而增强模型的实用性与准确性。工具调用扩展了模型的功能，使其能结合外部资源提供更精准的回答。</p>
<ul>
<li>创建工具（如数据库工具）</li>
<li>将工具绑定到模型</li>
<li>模型判断某个输入问题需要调用工具</li>
<li>工具调用生成结构化数据</li>
<li>使用工具（查询数据库）</li>
<li>得到工具使用的结果（数据结果）</li>
<li>返回给大模型增强回答</li>
</ul>
<p><img src="https://jing-images.oss-cn-beijing.aliyuncs.com/img/image-20250829144113686.png" alt="image-20250829144113686" style="zoom:67%;" /></p>
<ul>
<li>工具调用允许大模型通过调用工具来响应提示词</li>
<li>事实是模型只是生成工具参数，并不直接运行</li>
<li>本质上是模型生成的一段特定的结构化数据</li>
<li>并不是所有的模型都支持工具调用</li>
</ul>
<p><img src="https://jing-images.oss-cn-beijing.aliyuncs.com/img/image-20250829144444032.png" style="zoom:67%;" /></p>
<h2 id="绑定工具的代码示例"><a href="#绑定工具的代码示例" class="headerlink" title="绑定工具的代码示例"></a>绑定工具的代码示例</h2><p>两种方式：</p>
<ol>
<li><p>大模型直接绑定</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel, Field</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line">api_base = os.getenv(<span class="string">&quot;OPENAI_API_BASE&quot;</span>)</span><br><span class="line">api_key = os.getenv(<span class="string">&quot;OPENAI_API_KEY&quot;</span>)</span><br><span class="line"></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    temperature=<span class="number">0.0</span>,</span><br><span class="line">    base_url=api_base,</span><br><span class="line">    api_key=api_key</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#加法工具</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">add</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Add two integers.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    a: <span class="built_in">int</span> = Field(..., description=<span class="string">&quot;First integer&quot;</span>)</span><br><span class="line">    b: <span class="built_in">int</span> = Field(..., description=<span class="string">&quot;Second integer&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#乘法工具</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">multiply</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Multiply two integers.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    a: <span class="built_in">int</span> = Field(..., description=<span class="string">&quot;First integer&quot;</span>)</span><br><span class="line">    b: <span class="built_in">int</span> = Field(..., description=<span class="string">&quot;Second integer&quot;</span>)</span><br><span class="line">    </span><br><span class="line">tools = [add,multiply] <span class="comment"># 一个模型可以绑定多个工具的</span></span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line">query=<span class="string">&quot;3乘以12是多少？&quot;</span></span><br><span class="line">llm_with_tools.invoke(query).tool_calls <span class="comment"># 输出大模型调用的工具</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>使用@tool装饰器，注意：函数一定要有注释，这个会作为定义工具的描述</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> langchain_core.tools <span class="keyword">import</span> tool</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line">api_base = os.getenv(<span class="string">&quot;OPENAI_API_BASE&quot;</span>)</span><br><span class="line">api_key = os.getenv(<span class="string">&quot;OPENAI_API_KEY&quot;</span>)</span><br><span class="line"></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    temperature=<span class="number">0.0</span>,</span><br><span class="line">    base_url=api_base,</span><br><span class="line">    api_key=api_key</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">multiply</span>(<span class="params">a:<span class="built_in">int</span>,b:<span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Multiply two numbers.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> a*b</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(multiply.name)</span><br><span class="line"><span class="built_in">print</span>(multiply.description)</span><br><span class="line"><span class="built_in">print</span>(multiply.args)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;********************************************&quot;</span>)</span><br><span class="line">tools = [multiply]</span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line">query=<span class="string">&quot;3乘以12是多少？&quot;</span></span><br><span class="line">llm_with_tools.invoke(query).tool_calls</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>LangChain ModelsIO OutputParsers</p>
<p>LangChain已经可以轻松实现帮用户拿到大语言模型的输出，然而不难发现，前文介绍的模型调用，显示返回的内容通常是一个类（class）实例，其中包含了content以及其他一些额外的参数。</p>
<p>对于模型调用者来说，可能只关心content的内容，也就是模型对输入内容的回答，或者希望得到一个可操作的数据结构，比如JSON格式的数据。</p>
<h2 id="OutputParsers的优势"><a href="#OutputParsers的优势" class="headerlink" title="OutputParsers的优势"></a>OutputParsers的优势</h2><p>LangChain设计的初衷之一，旨在让用户更便捷地使用大模型，所以为了解决输出内容格式化的问题。</p>
<p>通过使用LangChain提供的解析器，用户可以更轻松地获取模型的输出，并直接处理或操作所需的内容，而无需进行额外的转换或处理。</p>
<h2 id="解析器类型"><a href="#解析器类型" class="headerlink" title="解析器类型"></a>解析器类型</h2><p>根据业务需求，开发者通常需要大模型返回一个结构化的数据，方便后续的逻辑可以根据这个数据进行进一步的处理。</p>
<p>然而不同的输入结果可能需要相对应的解析器来做处理，LangChain同样提供了几种常见的解析器类型：</p>
<ul>
<li>String解析器</li>
<li>Json解析器</li>
<li>Pydantic解析器</li>
<li>结构化输出解析器</li>
<li>OpenAI函数输出解析器</li>
</ul>
<h2 id="实战示例"><a href="#实战示例" class="headerlink" title="实战示例"></a>实战示例</h2><h3 id="String解析器"><a href="#String解析器" class="headerlink" title="String解析器"></a>String解析器</h3><p>LangChain提供了StrOutputParser，这是一个专门用来处理模型输出内容的解析器。当模型输出的内容是字符串格式的时候，StrOutputParser能够直接返回模型输出的content字符串内容。</p>
<p>这使得用户无需进行复杂的数据解析操作，可以直接获取模型输出的内容字符串，从而变更方便地进行后续处理或使用，代码示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> SystemMessage</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate, HumanMessagePromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> config_info <span class="keyword">import</span> get_config_info</span><br><span class="line"></span><br><span class="line"><span class="comment"># ChatGPT模型调用对象</span></span><br><span class="line">llm = OpenAI(openai_api_key=get_config_info().get(<span class="string">&#x27;key&#x27;</span>),</span><br><span class="line">             openai_api_base=get_config_info().get(<span class="string">&#x27;base&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">string_parser_demo</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    String解析器</span></span><br><span class="line"><span class="string">    StrOutputParser</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 提示词模版</span></span><br><span class="line">    messages = ChatPromptTemplate.from_messages([</span><br><span class="line">        SystemMessage(content=<span class="string">&quot;你是一个翻译各种语言的助手&quot;</span>),</span><br><span class="line">        HumanMessagePromptTemplate.from_template(<span class="string">&quot;把&#123;poetry&#125;的原文翻译为英文&quot;</span>)</span><br><span class="line">    ])</span><br><span class="line">    <span class="comment"># 输出解析器，转换为字符串</span></span><br><span class="line">    parser = StrOutputParser()</span><br><span class="line">    <span class="comment"># 调用链， 使用输出解析器</span></span><br><span class="line">    chain_with_parser = messages | llm | parser</span><br><span class="line">    <span class="comment"># 发送请求</span></span><br><span class="line">    res = chain_with_parser.invoke(&#123;<span class="string">&#x27;poetry&#x27;</span>: <span class="string">&#x27;静夜思&#x27;</span>&#125;)</span><br><span class="line">    <span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>
<h3 id="Json解析器"><a href="#Json解析器" class="headerlink" title="Json解析器"></a>Json解析器</h3><p>当模型输出的内容是一个JSON格式时，LangChain也提供了相应的解析器JsonOutputParser。该解析器能够根据JSON结构的内容，将其转换为Python对应的字典格式的数据，使得用户能够更方便地处理和操作模型输出的结果。代码示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># @Time: 2025/2/6 10:43</span></span><br><span class="line"><span class="comment"># @Author: lvjing</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> JsonOutputParser</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> config_info <span class="keyword">import</span> get_config_info</span><br><span class="line"></span><br><span class="line"><span class="comment"># ChatGPT模型调用对象</span></span><br><span class="line">llm = OpenAI(openai_api_key=get_config_info().get(<span class="string">&#x27;key&#x27;</span>),</span><br><span class="line">             openai_api_base=get_config_info().get(<span class="string">&#x27;base&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">json_parser_demo</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Json解析器</span></span><br><span class="line"><span class="string">    JsonOutputParser</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 输出解析器，转换为Json</span></span><br><span class="line">    parser = JsonOutputParser()</span><br><span class="line">    <span class="comment"># 提示词模版，输出json格式的回答</span></span><br><span class="line">    prompt = PromptTemplate(</span><br><span class="line">        template=<span class="string">&quot;根据用户输入，给出一段中文宣传语 \n&#123;format_instructions&#125;\n&#123;ads&#125;\n&quot;</span>,</span><br><span class="line">        input_variables=[<span class="string">&quot;ads&quot;</span>],</span><br><span class="line">        partial_variables=&#123;<span class="string">&quot;format_instructions&quot;</span>: parser.get_format_instructions()&#125;</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># 调用链， 包含json输出解析器</span></span><br><span class="line">    chain_with_parser = prompt | llm | parser</span><br><span class="line">    <span class="comment"># 发送请求</span></span><br><span class="line">    res = chain_with_parser.invoke(&#123;<span class="string">&#x27;ads&#x27;</span>: <span class="string">&#x27;音乐节&#x27;</span>&#125;)</span><br><span class="line">    <span class="built_in">print</span>(res)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">type</span>(res))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="Pydantic解析器"><a href="#Pydantic解析器" class="headerlink" title="Pydantic解析器"></a>Pydantic解析器</h3><p>LangChain还提供了对Pydantic模型的解析器：PydanticOutputParser</p>
<p>LangChain的Pydantic解析器可以将模型输出的内容解析为Pydantic模型所定义的数据结构。这使得用户可以更加方便的使用Pydantic的功能，例如数据验证、序列化和反序列化等，代码示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># @Time: 2025/2/6 10:43</span></span><br><span class="line"><span class="comment"># @Author: lvjing</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> PydanticOutputParser</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel, Field</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> config_info <span class="keyword">import</span> get_config_info</span><br><span class="line"></span><br><span class="line"><span class="comment"># ChatGPT模型调用对象</span></span><br><span class="line">llm = OpenAI(openai_api_key=get_config_info().get(<span class="string">&#x27;key&#x27;</span>),</span><br><span class="line">             openai_api_base=get_config_info().get(<span class="string">&#x27;base&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Translation</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    original_str: <span class="built_in">str</span> = Field(description=<span class="string">&quot;原始输入的值&quot;</span>)</span><br><span class="line">    trans_str: <span class="built_in">str</span> = Field(description=<span class="string">&quot;翻译后的值&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pydantic_parser_demo</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Pydantic解析器</span></span><br><span class="line"><span class="string">    PydanticOutputParser</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 使用Pydantic输出解析器解析Translation类</span></span><br><span class="line">    parser = PydanticOutputParser(pydantic_object=Translation)</span><br><span class="line">    <span class="comment"># 提示词模版，</span></span><br><span class="line">    prompt = PromptTemplate(</span><br><span class="line">        template=<span class="string">&quot;翻译用户输入的内容为英文 \n&#123;format_instructions&#125;\n&#123;query&#125;\n&quot;</span>,</span><br><span class="line">        input_variables=[<span class="string">&quot;query&quot;</span>],</span><br><span class="line">        partial_variables=&#123;<span class="string">&quot;format_instructions&quot;</span>: parser.get_format_instructions()&#125;</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># 调用链</span></span><br><span class="line">    chain_with_parser = prompt | llm | parser</span><br><span class="line">    <span class="comment"># 发送请求</span></span><br><span class="line">    res = chain_with_parser.invoke(&#123;<span class="string">&#x27;query&#x27;</span>: <span class="string">&#x27;赏花&#x27;</span>&#125;)</span><br><span class="line">    <span class="built_in">print</span>(res)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">type</span>(res))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="结构化输出解析器"><a href="#结构化输出解析器" class="headerlink" title="结构化输出解析器"></a>结构化输出解析器</h3><p>LangChain提供了一种自定义解析方案，即使用schema结构。用户可以根据需要定义自己的schema，并使用LangChain的StructuredOutputParser类来解析符合该schema的数据。</p>
<p>这种方式让用户能够更灵活地处理各种类型的模型输出数据，而无需依赖特定的数据验证库或框架。StructuredOutputParser为用户提供了一种通用的解析方式，使他们能够简单地将模型输出的数据转换为符合自定义schema的数据对象。代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># @Time: 2025/2/6 10:43</span></span><br><span class="line"><span class="comment"># @Author: lvjing</span></span><br><span class="line"><span class="keyword">from</span> langchain.output_parsers <span class="keyword">import</span> ResponseSchema, StructuredOutputParser</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> config_info <span class="keyword">import</span> get_config_info</span><br><span class="line"></span><br><span class="line"><span class="comment"># ChatGPT模型调用对象</span></span><br><span class="line">llm = OpenAI(openai_api_key=get_config_info().get(<span class="string">&#x27;key&#x27;</span>),</span><br><span class="line">             openai_api_base=get_config_info().get(<span class="string">&#x27;base&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">structured_parser_demo</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    结构化数据解析器</span></span><br><span class="line"><span class="string">    StructuredOutputParser</span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 定义schema对象</span></span><br><span class="line">    response_schema = [</span><br><span class="line">        ResponseSchema(name=<span class="string">&quot;slogan&quot;</span>, description=<span class="string">&quot;宣传语内容&quot;</span>),</span><br><span class="line">        ResponseSchema(name=<span class="string">&quot;req&quot;</span>, description=<span class="string">&quot;宣传语限制在10个字符内&quot;</span>)</span><br><span class="line">    ]</span><br><span class="line">    output_parser = StructuredOutputParser.from_response_schemas(response_schema)</span><br><span class="line">    <span class="comment"># 提示词模版，</span></span><br><span class="line">    prompt = PromptTemplate(</span><br><span class="line">        template=<span class="string">&quot;根据用户输入的商品给出宣传语\n&#123;format_instructions&#125;\n&#123;topic&#125;\n&quot;</span>,</span><br><span class="line">        input_variables=[<span class="string">&quot;topic&quot;</span>],</span><br><span class="line">        partial_variables=&#123;<span class="string">&quot;format_instructions&quot;</span>: output_parser.get_format_instructions()&#125;</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># 调用链</span></span><br><span class="line">    chain_with_parser = prompt | llm | output_parser</span><br><span class="line">    <span class="comment"># 发送请求</span></span><br><span class="line">    res = chain_with_parser.invoke(&#123;<span class="string">&#x27;topic&#x27;</span>: <span class="string">&#x27;音乐节&#x27;</span>&#125;)</span><br><span class="line">    <span class="built_in">print</span>(res)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">type</span>(res))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="OpenAI函数输出解析器"><a href="#OpenAI函数输出解析器" class="headerlink" title="OpenAI函数输出解析器"></a>OpenAI函数输出解析器</h3><p>LangChain支持解析OpenAI提供的函数调用，并提供了以下四种形式来处理输出结果：</p>
<ul>
<li>JsonOutputFunctionsParser:生成JSON格式的结果</li>
<li>JsonKeyOutputFunctionsParser:指定JSON中某个key对应的value</li>
<li>PydanticOutputFunctionsParser:解析Pydantic模型的结构</li>
<li>PydanticAttrOutputFunctionsParser:直接输出模型中某个参数的值</li>
</ul>
<h4 id="Json格式"><a href="#Json格式" class="headerlink" title="Json格式"></a>Json格式</h4><p><strong>JsonOutputFunctionsParser 和 JsonKeyOutputFunctionsParser(key_name=”ad”)</strong> </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># @Time: 2025/2/6 10:43</span></span><br><span class="line"><span class="comment"># @Author: lvjing</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers.openai_functions <span class="keyword">import</span> JsonOutputFunctionsParser, JsonKeyOutputFunctionsParser</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> config_info <span class="keyword">import</span> get_config_info</span><br><span class="line"></span><br><span class="line">model = ChatOpenAI(openai_api_key=get_config_info().get(<span class="string">&#x27;key&#x27;</span>),</span><br><span class="line">                   openai_api_base=get_config_info().get(<span class="string">&#x27;base&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">openai_json_demo</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    OpenAI函数输出解析器--JSON格式</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 自定函数</span></span><br><span class="line">    functions = [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;advertisement&quot;</span>,</span><br><span class="line">            <span class="string">&quot;description&quot;</span>: <span class="string">&quot;一段广告词&quot;</span>,</span><br><span class="line">            <span class="string">&quot;parameters&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>,</span><br><span class="line">                <span class="string">&quot;properties&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;goods&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>, <span class="string">&quot;description&quot;</span>: <span class="string">&quot;要进行广告的产品&quot;</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    <span class="string">&quot;ad&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>, <span class="string">&quot;description&quot;</span>: <span class="string">&quot;广告词&quot;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="string">&quot;required&quot;</span>: [<span class="string">&quot;goods&quot;</span>, <span class="string">&quot;ad&quot;</span>]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">    <span class="comment"># 提示词模版</span></span><br><span class="line">    prompt = ChatPromptTemplate.from_template(<span class="string">&quot;给出一个关于&#123;goods&#125;的广告宣传语&quot;</span>)</span><br><span class="line">    <span class="comment"># 创建调用链，包含输出解析器</span></span><br><span class="line">    chain_json_with_parser = prompt | model.bind(function_call=&#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;advertisement&quot;</span>&#125;,</span><br><span class="line">                                                 functions=functions) | JsonOutputFunctionsParser()</span><br><span class="line">    res = chain_json_with_parser.invoke(&#123;<span class="string">&quot;goods&quot;</span>: <span class="string">&quot;冰淇淋&quot;</span>&#125;)</span><br><span class="line">    <span class="built_in">print</span>(res)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">type</span>(res))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;================================&quot;</span>)</span><br><span class="line"></span><br><span class="line">    chain_json_key_with_parser = prompt | model.bind(function_call=&#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;advertisement&quot;</span>&#125;,</span><br><span class="line">                                                     functions=functions) | JsonKeyOutputFunctionsParser(key_name=<span class="string">&quot;ad&quot;</span>)</span><br><span class="line">    res_key = chain_json_key_with_parser.invoke(&#123;<span class="string">&quot;goods&quot;</span>: <span class="string">&quot;冰淇淋&quot;</span>&#125;)</span><br><span class="line">    <span class="built_in">print</span>(res_key)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">type</span>(res_key))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="Pydantic模型"><a href="#Pydantic模型" class="headerlink" title="Pydantic模型"></a>Pydantic模型</h4><p><strong>PydanticOutputFunctionsParser(pydantic_schema=Advertisement) 和 PydanticAttrOutputFunctionsParser(pydantic_schema=Advertisement, attr_name=”ads”)</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># @Time: 2025/2/6 10:43</span></span><br><span class="line"><span class="comment"># @Author: lvjing</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers.openai_functions <span class="keyword">import</span> PydanticOutputFunctionsParser, \</span><br><span class="line">    PydanticAttrOutputFunctionsParser</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.utils.function_calling <span class="keyword">import</span> convert_to_openai_function</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel, Field</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> config_info <span class="keyword">import</span> get_config_info</span><br><span class="line"></span><br><span class="line">model = ChatOpenAI(openai_api_key=get_config_info().get(<span class="string">&#x27;key&#x27;</span>),</span><br><span class="line">                   openai_api_base=get_config_info().get(<span class="string">&#x27;base&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Advertisement</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Pydantic模型</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    goods: <span class="built_in">str</span> = Field(description=<span class="string">&quot;物品&quot;</span>)</span><br><span class="line">    ads: <span class="built_in">str</span> = Field(description=<span class="string">&quot;宣传语&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pydantic_json_demo</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    OpenAI函数输出解析器--Pydantic模型</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 定义解析器</span></span><br><span class="line">    parser = PydanticOutputFunctionsParser(pydantic_schema=Advertisement)</span><br><span class="line">    <span class="comment"># 创建调用函数(转换为列表)</span></span><br><span class="line">    openai_functions = [convert_to_openai_function(Advertisement)]</span><br><span class="line">    <span class="comment"># 提示词模版</span></span><br><span class="line">    prompt = ChatPromptTemplate.from_template(<span class="string">&quot;给出一个关于&#123;goods&#125;的广告宣传语&quot;</span>)</span><br><span class="line">    <span class="comment"># 创建调用链</span></span><br><span class="line">    chain_pydantic_parser = prompt | model.bind(functions=openai_functions) | parser</span><br><span class="line">    res = chain_pydantic_parser.invoke(&#123;<span class="string">&quot;goods&quot;</span>: <span class="string">&quot;饮料&quot;</span>&#125;)</span><br><span class="line">    <span class="built_in">print</span>(res)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">type</span>(res))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;================================&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义解析器</span></span><br><span class="line">    parser_attr = PydanticAttrOutputFunctionsParser(pydantic_schema=Advertisement, attr_name=<span class="string">&quot;ads&quot;</span>)</span><br><span class="line">    <span class="comment"># 创建调用链</span></span><br><span class="line">    chain_pydantic_parser_attr = prompt | model.bind(functions=openai_functions) | parser_attr</span><br><span class="line">    res_attr = chain_pydantic_parser_attr.invoke(&#123;<span class="string">&quot;goods&quot;</span>: <span class="string">&quot;饮料&quot;</span>&#125;)</span><br><span class="line">    <span class="built_in">print</span>(res_attr)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">type</span>(res_attr))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/LangChain/" rel="tag"># LangChain</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/02/05/ai/langchain/3-langchain-PromptTemple/" rel="prev" title="LangChain组件PromptTemple">
      <i class="fa fa-chevron-left"></i> LangChain组件PromptTemple
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/02/06/ai/langchain/7-langchain-rag-embed/" rel="next" title="LangChain RAG之向量">
      LangChain RAG之向量 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#ChatModels-amp-LLMs"><span class="nav-number">1.</span> <span class="nav-text">ChatModels &amp; LLMs</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8E%A5%E5%85%A5%E7%A4%BA%E4%BE%8B"><span class="nav-number">1.1.</span> <span class="nav-text">大模型的接入示例</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#OpenAI%E6%8E%A5%E5%85%A5"><span class="nav-number">1.1.1.</span> <span class="nav-text">OpenAI接入</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DeepSeek%E6%8E%A5%E5%85%A5"><span class="nav-number">1.1.2.</span> <span class="nav-text">DeepSeek接入</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Anthropic%E6%8E%A5%E5%85%A5"><span class="nav-number">1.1.3.</span> <span class="nav-text">Anthropic接入</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A0%87%E5%87%86%E5%8F%82%E6%95%B0%E3%80%81%E4%BA%8B%E4%BB%B6%E3%80%81%E4%B8%8E%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA"><span class="nav-number">2.</span> <span class="nav-text">标准参数、事件、与输入输出</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A0%87%E5%87%86%E5%8F%82%E6%95%B0"><span class="nav-number">2.1.</span> <span class="nav-text">标准参数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A1%A5%E5%85%A8%E5%8F%82%E6%95%B0-Completion-Params"><span class="nav-number">2.1.1.</span> <span class="nav-text">补全参数 (Completion Params)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%8F%82%E6%95%B0-Client-Params"><span class="nav-number">2.1.2.</span> <span class="nav-text">客户端参数 (Client Params)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A0%87%E5%87%86%E4%BA%8B%E4%BB%B6"><span class="nav-number">2.2.</span> <span class="nav-text">标准事件</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B6%E4%BB%96%E6%9C%89%E7%94%A8%E4%BA%8B%E4%BB%B6"><span class="nav-number">2.2.1.</span> <span class="nav-text">其他有用事件</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1%E7%9A%84%E6%A0%BC%E5%BC%8F"><span class="nav-number">2.3.</span> <span class="nav-text">数据通信的格式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#OpenAI-Messages"><span class="nav-number">2.3.1.</span> <span class="nav-text">OpenAI Messages</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LangChain-Messages"><span class="nav-number">2.3.2.</span> <span class="nav-text">LangChain Messages</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AIMessage"><span class="nav-number">2.3.3.</span> <span class="nav-text">AIMessage</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AA%97%E5%8F%A3%E4%B8%8Etoken"><span class="nav-number">3.</span> <span class="nav-text">模型上下文窗口与token</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AA%97%E5%8F%A3"><span class="nav-number">3.1.</span> <span class="nav-text">什么是上下文窗口</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%9A%84token"><span class="nav-number">3.2.</span> <span class="nav-text">模型的token</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#token%E7%9A%84%E7%9B%91%E6%8E%A7%E4%B8%8E%E8%BF%BD%E8%B8%AA"><span class="nav-number">3.3.</span> <span class="nav-text">token的监控与追踪</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%80%9F%E7%8E%87%E9%99%90%E5%88%B6%E4%B8%8E%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6"><span class="nav-number">4.</span> <span class="nav-text">速率限制与缓存机制</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%B7%A5%E5%85%B7%E8%B0%83%E7%94%A8%E5%8E%9F%E7%90%86"><span class="nav-number">5.</span> <span class="nav-text">大模型工具调用原理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%91%E5%AE%9A%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B"><span class="nav-number">5.1.</span> <span class="nav-text">绑定工具的代码示例</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OutputParsers%E7%9A%84%E4%BC%98%E5%8A%BF"><span class="nav-number">5.2.</span> <span class="nav-text">OutputParsers的优势</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A7%A3%E6%9E%90%E5%99%A8%E7%B1%BB%E5%9E%8B"><span class="nav-number">5.3.</span> <span class="nav-text">解析器类型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E6%88%98%E7%A4%BA%E4%BE%8B"><span class="nav-number">5.4.</span> <span class="nav-text">实战示例</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#String%E8%A7%A3%E6%9E%90%E5%99%A8"><span class="nav-number">5.4.1.</span> <span class="nav-text">String解析器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Json%E8%A7%A3%E6%9E%90%E5%99%A8"><span class="nav-number">5.4.2.</span> <span class="nav-text">Json解析器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pydantic%E8%A7%A3%E6%9E%90%E5%99%A8"><span class="nav-number">5.4.3.</span> <span class="nav-text">Pydantic解析器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%93%E6%9E%84%E5%8C%96%E8%BE%93%E5%87%BA%E8%A7%A3%E6%9E%90%E5%99%A8"><span class="nav-number">5.4.4.</span> <span class="nav-text">结构化输出解析器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#OpenAI%E5%87%BD%E6%95%B0%E8%BE%93%E5%87%BA%E8%A7%A3%E6%9E%90%E5%99%A8"><span class="nav-number">5.4.5.</span> <span class="nav-text">OpenAI函数输出解析器</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Json%E6%A0%BC%E5%BC%8F"><span class="nav-number">5.4.5.1.</span> <span class="nav-text">Json格式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Pydantic%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.4.5.2.</span> <span class="nav-text">Pydantic模型</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Jean Lv"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Jean Lv</p>
  <div class="site-description" itemprop="description">涉猎的主要编程语言Java、Python, 领域软件测试、AI测试开发相关</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">153</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">28</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jean Lv</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  

  

    </div>
</body>
</html>
